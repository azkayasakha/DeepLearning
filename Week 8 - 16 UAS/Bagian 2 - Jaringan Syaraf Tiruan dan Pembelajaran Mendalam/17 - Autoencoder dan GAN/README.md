---

# ğŸ“˜ Chapter 17 â€“ Representation Learning and Generative Learning Using Autoencoders and GANs

---

## ğŸ¯ Tujuan Bab Ini:

* Memahami **autoencoder**: model untuk kompresi & rekonstruksi data
* Latih model untuk belajar **representasi tersembunyi**
* Memahami **generative learning**: model belajar menghasilkan data baru
* Latih dan gunakan **Variational Autoencoders (VAE)** dan **Generative Adversarial Networks (GANs)**

---

## ğŸ§  1. Apa itu Representation Learning?

Model **belajar fitur sendiri** dari data tanpa label eksplisit.

Contoh:

* Autoencoder mempelajari representasi ringkas dari input
* GAN belajar membuat data baru yang mirip distribusi aslinya

---

## ğŸ› ï¸ 2. Autoencoder: Encoder + Decoder

### Arsitektur Umum:

```
Input â†’ Encoder â†’ Latent Vector â†’ Decoder â†’ Output â‰ˆ Input
```

* **Encoder**: Kompres input jadi representasi (latent space)
* **Decoder**: Rekonstruksi input dari latent space

### Jenis:

| Jenis Autoencoder | Fungsi Khusus                     |
| ----------------- | --------------------------------- |
| Undercomplete     | Dimensi kecil â†’ kompresi          |
| Denoising         | Input rusak â†’ belajar bersihkan   |
| Sparse            | Latent harus sparing (banyak nol) |
| Variational (VAE) | Probabilistik â†’ generatif         |

---

## âš™ï¸ 3. Loss Function Autoencoder

Biasanya:

* **MSE** antara input dan output

```python
loss = keras.losses.mean_squared_error(inputs, outputs)
```

---

## ğŸ”„ 4. Denoising Autoencoder

* Tambahkan noise ke input â†’ target tetap input asli
* Membantu model belajar representasi **robust**

---

## ğŸŒ€ 5. Variational Autoencoder (VAE)

Berbeda dari autoencoder biasa:

* Alih-alih titik, encoder hasilkan **distribusi (mean dan var)**
* Sampling dari distribusi â†’ generatif!

### Arsitektur:

```
Input â†’ Encoder â†’ (Î¼, Ïƒ) â†’ Sampling â†’ Decoder â†’ Output
```

### Loss VAE = Rekonstruksi + Regularisasi (KL Divergence)

```text
Loss = MSE + KL(N(Î¼,ÏƒÂ²) || N(0,1))
```

---

## ğŸ¤– 6. Generative Adversarial Network (GAN)

Dua model saling melawan:

* **Generator**: membuat data palsu
* **Discriminator**: membedakan data nyata vs palsu

### Arsitektur GAN:

```
Noise â†’ Generator â†’ Fake data
Real/Fake data â†’ Discriminator â†’ Real or Fake
```

### Latih dengan cara:

* Generator ingin mengecoh discriminator
* Discriminator ingin menangkap fake

---

## ğŸ§ª 7. Loss GAN

* Discriminator:

  ```text
  Loss = -log(D(real)) - log(1 - D(fake))
  ```
* Generator:

  ```text
  Loss = -log(D(fake))
  ```

---

## ğŸ¨ 8. Aplikasi Autoencoder & GAN

| Model       | Aplikasi                                |
| ----------- | --------------------------------------- |
| Autoencoder | Kompresi, denoising, anomaly detection  |
| VAE         | Image generation, latent space sampling |
| GAN         | Image synthesis, data augmentation      |

---

## ğŸ“‘ Ringkasan Inti Bab Ini:

* Autoencoder belajar representasi dari input tanpa supervisi
* VAE menambahkan probabilistik dan regularisasi â†’ generatif
* GAN gunakan dua model bertanding untuk menghasilkan data mirip aslinya
* VAE dan GAN bisa digunakan untuk visualisasi, deteksi anomali, dan generasi data

---