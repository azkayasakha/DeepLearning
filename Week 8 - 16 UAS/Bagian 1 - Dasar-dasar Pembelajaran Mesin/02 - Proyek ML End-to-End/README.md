---

# ğŸ“˜ Chapter 2 â€“ End-to-End Machine Learning Project

---

## ğŸ¯ Tujuan Bab Ini:

* Menunjukkan proses lengkap membangun proyek Machine Learning dari awal hingga akhir.
* Menggunakan dataset **California Housing**.
* Fokus pada **praktik nyata**: pembersihan data, eksplorasi, persiapan data, pelatihan model, evaluasi, dan simpan model.

---

## ğŸ—‚ï¸ 1. Mengerti Masalah dan Tujuan Bisnis

> Proyek ini mensimulasikan skenario di mana kamu bekerja untuk perusahaan real estate yang ingin membuat sistem prediksi harga rumah berdasarkan data sensus California.

ğŸ” **Pertanyaan bisnis:**
Bagaimana kita bisa memprediksi harga rumah median di suatu daerah berdasarkan informasi demografis dan geografis?

ğŸ¯ **Target ML:**
Prediksi numerik â†’ berarti kita berhadapan dengan **regression problem**.

---

## ğŸ“Š 2. Memperoleh Data

Dataset yang digunakan:

* **California Housing Dataset** (dari tahun 1990)
* Tersedia langsung di `sklearn.datasets.fetch_california_housing()`

Opsi lain:

* File CSV (bila di-download terpisah dari repositori buku)
* Atau lewat repositori GitHub AurÃ©lien GÃ©ron

---

## ğŸ” 3. Jelajahi Data dan Pahami

Gunakan statistik deskriptif dan visualisasi untuk memahami data:

* Cek info dataset (jumlah baris, kolom, missing value)
* Cek distribusi fitur
* Gunakan histogram, scatter plot, dan correlation matrix

ğŸ¯ Tujuannya:

* Menemukan pola
* Mengetahui anomali
* Menentukan preprocessing yang dibutuhkan

---

## ğŸ§¹ 4. Membagi Dataset (Training/Test Set)

Kenapa harus dibagi?

* Agar kita bisa mengevaluasi performa model pada **data yang belum pernah dilihat sebelumnya**.
* Biasanya digunakan pembagian **80% training â€“ 20% test**.

ğŸ’¡ Teknik tambahan:

* **Stratified sampling**: memastikan distribusi subset data tetap representatif (misal: pendapatan menengah).

---

## ğŸ§½ 5. Pembersihan dan Persiapan Data

### Langkah umum:

* Menangani **missing value**
* Mengubah **kategori ke numerik**
* **Feature scaling** (normalisasi/standarisasi)
* **Feature engineering** (membuat fitur baru dari yang ada)

ğŸ”§ Tools yang digunakan:

* `SimpleImputer`, `OneHotEncoder`, `StandardScaler`, dan `Pipeline` dari `scikit-learn`

---

## ğŸ—ï¸ 6. Pilih Model dan Latih

* Mulai dari model sederhana: **Linear Regression**
* Coba model lebih kompleks: **Decision Tree**, **Random Forest**
* Gunakan **cross-validation** untuk menghindari overfitting

---

## ğŸ“ˆ 7. Evaluasi Model

* Untuk regresi: **RMSE**, **MAE**
* Gunakan **cross-validation** untuk mengevaluasi secara lebih akurat
* Bandingkan beberapa model berdasarkan performa

---

## ğŸ”„ 8. Tuning dan Fine-tuning Model

Gunakan:

* **Grid Search**: mencoba semua kombinasi parameter
* **Randomized Search**: sampling parameter secara acak
* Validasi akhir pada test set

---

## ğŸ’¾ 9. Simpan dan Deploy Model

* Simpan model terlatih dengan `joblib` atau `pickle`
* Bisa digunakan kembali tanpa melatih ulang
* Model bisa di-*deploy* ke aplikasi web, API, atau sistem lain

---

## ğŸ“‘ Ringkasan Alur Proyek ML End-to-End:

1. **Definisikan masalah**
2. **Dapatkan data**
3. **Eksplorasi data awal**
4. **Buat set validasi**
5. **Siapkan data**
6. **Pilih dan latih model**
7. **Evaluasi model**
8. **Perbaiki dan tuning model**
9. **Uji model akhir**
10. **Simpan dan deploy model**

---

ğŸ“Œ Setelah ini, kita bisa lanjut ke **kode praktikalnya**, mengikuti struktur langkah di atas secara langsung.